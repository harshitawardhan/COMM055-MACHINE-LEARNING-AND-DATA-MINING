{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i6ZNg9E83Oj"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz5LcULM9LBx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Direct download URL for the Google Drive file\n",
        "CSV_URL = 'https://drive.google.com/uc?export=download&id=1iyhG9KK2SpLS1BxP6axyTMZw7RMjWgwR'\n",
        "\n",
        "try:\n",
        "    # Read the CSV file directly into a DataFrame\n",
        "    rent_apartments_dataset = pd.read_csv(CSV_URL)\n",
        "except Exception as e:\n",
        "    print(\"Error reading the CSV file:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TbbImBC9Pg8"
      },
      "outputs": [],
      "source": [
        "    print(rent_apartments_dataset.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KaAyMUt9gy_"
      },
      "outputs": [],
      "source": [
        "# Print all column names as a list\n",
        "print(rent_apartments_dataset.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7wYhUT91YyR"
      },
      "source": [
        "rent_apartments_dataset\n",
        "Exp - 1 XGBoost regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtbBxSK2x0zn",
        "outputId": "bb4d1c3a-7098-4f9b-bf82-e9367e850469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.26\n",
            "Mean Absolute Error: 0.36\n",
            "R2 Score: 0.75\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Prepare features and target\n",
        "X = rent_apartments_dataset.drop('price', axis=1)  # use all other columns as features\n",
        "y = rent_apartments_dataset['price']  # 'price' as the target variable\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
        "\n",
        "# Fit the model\n",
        "xgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = xgb_regressor.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "print(f'R2 Score: {r2:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k- fold cross validation\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_results = cross_val_score(xgb_regressor, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calculate mean and standard deviation of the cross-validated MSE\n",
        "mean_cv_mse = -cv_results.mean()\n",
        "std_cv_mse = cv_results.std()\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f'10-fold Cross-validated Mean Squared Error: {mean_cv_mse:.2f}')\n",
        "print(f'10-fold Cross-validated Standard Deviation of MSE: {std_cv_mse:.2f}')\n",
        "\n",
        "# Fit the model on the full training set\n",
        "xgb_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = xgb_regressor.predict(X_test)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Test Set Mean Squared Error: {mse:.2f}')\n",
        "print(f'Test Set Mean Absolute Error: {mae:.2f}')\n",
        "print(f'Test Set R2 Score: {r2:.2f}')"
      ],
      "metadata": {
        "id": "_AzSeKOW8NLq",
        "outputId": "e031f4db-1001-4e40-b34d-c3afa3b561f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-fold Cross-validated Mean Squared Error: 0.28\n",
            "10-fold Cross-validated Standard Deviation of MSE: 0.03\n",
            "Test Set Mean Squared Error: 0.26\n",
            "Test Set Mean Absolute Error: 0.36\n",
            "Test Set R2 Score: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p26fVRa1XQt"
      },
      "source": [
        "rent_apartments_dataset Exp 2 hyperparameter tuning for the XGBoost regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V6j2-ourG0U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming rent_apartments_dataset is loaded and available\n",
        "\n",
        "# Prepare features and target\n",
        "X = rent_apartments_dataset.drop('price', axis=1)  # use all other columns as features\n",
        "y = rent_apartments_dataset['price']  # 'price' as the target variable\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the parameter grid to tune\n",
        "params = {\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "\n",
        "# Setup the grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=params, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "# Fit grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best MSE score found: \", -grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "print(f'R2 Score: {r2:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcHvb9DHFMST"
      },
      "source": [
        "rent_apartments_dataset Exp 3 GridSearchCV for XGBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fdT_FbcrG6r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming rent_apartments_dataset is already loaded and contains the data\n",
        "\n",
        "# Prepare features and target\n",
        "X = rent_apartments_dataset.drop('price', axis=1)  # use all other columns as features\n",
        "y = rent_apartments_dataset['price']  # 'price' as the target variable\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost regressor\n",
        "xgb_regressor = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42)\n",
        "\n",
        "# Setup the GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
        "\n",
        "# Fit grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and best MSE from GridSearchCV\n",
        "best_params = grid_search.best_params_\n",
        "best_mse = -grid_search.best_score_  # Convert from negative MSE to positive MSE\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "best_regressor = grid_search.best_estimator_\n",
        "y_pred = best_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the best model using regression metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation and best parameter results\n",
        "print(\"Best parameters found: \", best_params)\n",
        "print(\"Best MSE from CV: \", best_mse)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'Mean Absolute Error: {mae:.2f}')\n",
        "print(f'R2 Score: {r2:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3UrWI76MIRE"
      },
      "source": [
        "rent_apartments_dataset Exp 4 Bayesian optimization for your XGBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyA1ajqKvIGb"
      },
      "outputs": [],
      "source": [
        "pip install bayesian-optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTqpfevJu1qS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Function to be optimized\n",
        "def xgb_evaluate(max_depth, learning_rate, n_estimators, colsample_bytree, subsample):\n",
        "    params = {\n",
        "        'eval_metric': 'rmse',\n",
        "        'max_depth': int(max_depth),\n",
        "        'learning_rate': learning_rate,\n",
        "        'n_estimators': int(n_estimators),\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'subsample': subsample,\n",
        "        'objective': 'reg:squarederror',\n",
        "        'silent': 1,\n",
        "    }\n",
        "    xgb_reg = xgb.XGBRegressor(**params)\n",
        "    xgb_reg.fit(X_train, y_train)\n",
        "    predictions = xgb_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    return -mse\n",
        "\n",
        "# Prepare features and target\n",
        "X = rent_apartments_dataset.drop('price', axis=1)  # use all other columns as features\n",
        "y = rent_apartments_dataset['price']  # 'price' as the target variable\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bayesian optimization\n",
        "xgb_bo = BayesianOptimization(xgb_evaluate, {\n",
        "    'max_depth': (3, 10),\n",
        "    'learning_rate': (0.01, 0.3),\n",
        "    'n_estimators': (50, 300),\n",
        "    'colsample_bytree': (0.3, 0.9),\n",
        "    'subsample': (0.5, 1.0)\n",
        "}, random_state=0)\n",
        "\n",
        "xgb_bo.maximize(init_points=2, n_iter=10)\n",
        "\n",
        "# Extract the best parameters\n",
        "best_params = xgb_bo.max['params']\n",
        "best_params['max_depth'] = int(best_params['max_depth'])\n",
        "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
        "print(\"Best parameters: \", best_params)\n",
        "\n",
        "# Re-train the model with the best parameters\n",
        "best_xgb = xgb.XGBRegressor(**best_params)\n",
        "best_xgb.fit(X_train, y_train)\n",
        "best_y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "best_mse = mean_squared_error(y_test, best_y_pred)\n",
        "best_mae = mean_absolute_error(y_test, best_y_pred)\n",
        "best_r2 = r2_score(y_test, best_y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Optimized Mean Squared Error: {best_mse:.2f}')\n",
        "print(f'Optimized Mean Absolute Error: {best_mae:.2f}')\n",
        "print(f'Optimized R2 Score: {best_r2:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1uR9svoc7L6"
      },
      "outputs": [],
      "source": [
        "pip install matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwRQogyac2iM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Data preparation\n",
        "data = {\n",
        "    'Experiment': ['XGBoost Regressor', 'Hyperparameter Tuning', 'GridSearchCV', 'Bayesian Optimization'],\n",
        "    'MSE': [0.26, 0.19, 0.19, 0.19],\n",
        "    'MAE': [0.36, 0.30, 0.30, 0.30],\n",
        "    'R2 Score': [0.75, 0.81, 0.82, 0.82]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Setting the style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Setting the plot size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting MSE\n",
        "plt.plot(df['Experiment'], df['MSE'], marker='o', label='MSE', color='blue')\n",
        "\n",
        "# Plotting MAE\n",
        "plt.plot(df['Experiment'], df['MAE'], marker='o', label='MAE', color='green')\n",
        "\n",
        "# Plotting R2 Score\n",
        "plt.plot(df['Experiment'], df['R2 Score'], marker='o', label='R2 Score', color='red')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Performance Comparison of XGBoost Models', fontsize=14)\n",
        "plt.xlabel('Experiment', fontsize=12)\n",
        "plt.ylabel('Values', fontsize=12)\n",
        "plt.legend(title='Metrics')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEnoiwdENG1U"
      },
      "source": [
        "adult_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JyAMtdKlGqv"
      },
      "outputs": [],
      "source": [
        "# Direct download URL for the Google Drive file\n",
        "CSV_URL = 'https://drive.google.com/uc?export=download&id=1K2zmMuv0mj-vTdVmL7skUD_uFND0gg0U'\n",
        "\n",
        "try:\n",
        "    # Read the CSV file directly into a DataFrame\n",
        "    adult_dataset = pd.read_csv(CSV_URL)\n",
        "except Exception as e:\n",
        "    print(\"Error reading the CSV file:\", e)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWfUygF2lGth",
        "outputId": "0a7d012a-ced6-4aa7-f97a-7513640b0b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  fnlwgt  education-num  sex  capital-gain  capital-loss  \\\n",
            "0   22  231912             11    0             0             0   \n",
            "1   79  165209              9    1             0             0   \n",
            "2   43   47818             13    0             0             0   \n",
            "3   29  565769              1    1             0             0   \n",
            "4   57  222216             11    0             0             0   \n",
            "5   51  136823              9    0             0             0   \n",
            "6   52  203392             10    1          5013             0   \n",
            "7   71  162297              9    0             0             0   \n",
            "8   28  187479             10    1             0             0   \n",
            "9   25  186294              9    0             0             0   \n",
            "\n",
            "   hours-per-week  native-country  income  workclass_Other  ...  \\\n",
            "0              37              39       0                0  ...   \n",
            "1              40              39       0                0  ...   \n",
            "2              40              39       0                0  ...   \n",
            "3              40              35       0                0  ...   \n",
            "4              38              39       0                0  ...   \n",
            "5              32              39       0                0  ...   \n",
            "6              40              39       0                0  ...   \n",
            "7              20              39       0                0  ...   \n",
            "8              55              39       0                0  ...   \n",
            "9              50              39       0                0  ...   \n",
            "\n",
            "   race_Asian-Pac-Islander  race_Black  race_Other  race_White  \\\n",
            "0                        0           0           0           1   \n",
            "1                        0           0           0           1   \n",
            "2                        0           0           0           1   \n",
            "3                        0           1           0           0   \n",
            "4                        0           0           0           1   \n",
            "5                        0           0           0           1   \n",
            "6                        0           0           0           1   \n",
            "7                        0           0           0           1   \n",
            "8                        0           0           0           1   \n",
            "9                        0           0           0           1   \n",
            "\n",
            "   age_standardized  fnlwgt_standardized  education-num_standardized  \\\n",
            "0         -1.432592             0.414917                    0.154377   \n",
            "1          2.967552            -0.228631                   -0.611251   \n",
            "2          0.188514            -1.361216                    0.920005   \n",
            "3         -0.892223             3.635959                   -3.673763   \n",
            "4          1.269251             0.321370                    0.154377   \n",
            "5          0.806078            -0.502499                   -0.611251   \n",
            "6          0.883273             0.139757                   -0.228437   \n",
            "7          2.349988            -0.256726                   -0.611251   \n",
            "8         -0.969419            -0.013771                   -0.228437   \n",
            "9         -1.201006            -0.025204                   -0.611251   \n",
            "\n",
            "   capital-gain_standardized  capital-loss_standardized  \\\n",
            "0                  -0.196967                  -0.258317   \n",
            "1                  -0.196967                  -0.258317   \n",
            "2                  -0.196967                  -0.258317   \n",
            "3                  -0.196967                  -0.258317   \n",
            "4                  -0.196967                  -0.258317   \n",
            "5                  -0.196967                  -0.258317   \n",
            "6                   0.274471                  -0.258317   \n",
            "7                  -0.196967                  -0.258317   \n",
            "8                  -0.196967                  -0.258317   \n",
            "9                  -0.196967                  -0.258317   \n",
            "\n",
            "   hours-per-week_standardized  \n",
            "0                    -0.421552  \n",
            "1                    -0.174957  \n",
            "2                    -0.174957  \n",
            "3                    -0.174957  \n",
            "4                    -0.339354  \n",
            "5                    -0.832543  \n",
            "6                    -0.174957  \n",
            "7                    -1.818923  \n",
            "8                     1.058017  \n",
            "9                     0.647026  \n",
            "\n",
            "[10 rows x 47 columns]\n"
          ]
        }
      ],
      "source": [
        "    print(adult_dataset.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6SEXwBllGwq"
      },
      "outputs": [],
      "source": [
        "# Print all column names as a list\n",
        "print(adult_dataset.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv8GzCb2_IFx"
      },
      "source": [
        "Exp1 XGBoost - adult_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo44ag44h_rw",
        "outputId": "41f90c53-4076-44e9-d54b-e40af4e3a971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.86      0.83      0.84      2342\n",
            "        >50K       0.83      0.86      0.85      2333\n",
            "\n",
            "    accuracy                           0.84      4675\n",
            "   macro avg       0.85      0.84      0.84      4675\n",
            "weighted avg       0.85      0.84      0.84      4675\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# Encode 'income' if it is categorical\n",
        "le = LabelEncoder()\n",
        "adult_dataset['income'] = le.fit_transform(adult_dataset['income'])\n",
        "\n",
        "# Prepare features and target\n",
        "X = adult_dataset.drop('income', axis=1)\n",
        "y = adult_dataset['income']\n",
        "\n",
        "# Handle categorical variables if any (example using get_dummies)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "\n",
        "# Fit the model\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_metrics = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(\"Classification Report:\")\n",
        "print(classification_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k- fold cross validation\n",
        "\n",
        "# Perform K-Fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_results = cross_val_score(classifier, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "# Calculate mean and standard deviation of the cross-validated accuracy\n",
        "mean_cv_accuracy = cv_results.mean()\n",
        "std_cv_accuracy = cv_results.std()\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f'10-fold Cross-validated Accuracy: {mean_cv_accuracy:.2f}')\n",
        "print(f'10-fold Cross-validated Standard Deviation of Accuracy: {std_cv_accuracy:.2f}')\n",
        "\n",
        "# Fit the model on the full training set\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_metrics = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
        "\n",
        "# Print the evaluation results\n",
        "print(f'Test Set Accuracy: {accuracy:.2f}')\n",
        "print(\"Classification Report:\")\n",
        "print(classification_metrics)"
      ],
      "metadata": {
        "id": "uQ-s5VIL9XmI",
        "outputId": "0f3c7e30-b336-47f3-e239-4242ab6e102d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10-fold Cross-validated Accuracy: 0.84\n",
            "10-fold Cross-validated Standard Deviation of Accuracy: 0.01\n",
            "Test Set Accuracy: 0.84\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.86      0.83      0.84      2342\n",
            "        >50K       0.83      0.86      0.85      2333\n",
            "\n",
            "    accuracy                           0.84      4675\n",
            "   macro avg       0.85      0.84      0.84      4675\n",
            "weighted avg       0.85      0.84      0.84      4675\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuVnmlZJBzkq"
      },
      "source": [
        "Exp 2 Hyperparameter tuning for the XGBoost regressor - adult_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1-ioQr5lG5A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode 'income' if it is categorical\n",
        "le = LabelEncoder()\n",
        "adult_dataset['income'] = le.fit_transform(adult_dataset['income'])\n",
        "\n",
        "# Prepare features and target\n",
        "X = adult_dataset.drop('income', axis=1)\n",
        "y = adult_dataset['income']\n",
        "\n",
        "# Handle categorical variables if any (example using get_dummies)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'colsample_bytree': [0.3, 0.5, 0.7, 1],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Setup the grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "\n",
        "# Fit grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best accuracy found: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_metrics = classification_report(y_test, y_pred, target_names=['<=50K', '>50K'])\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy:.2f}')\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoUBARDENfDi"
      },
      "source": [
        "Exp 3 GridSearchCV for XGBoost adult_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH9Zz43VlG7R",
        "outputId": "303fe40b-948f-4638-90de-ef96691d6c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming 'income' is the target and it is categorical\n",
        "le = LabelEncoder()\n",
        "adult_dataset['income'] = le.fit_transform(adult_dataset['income'])\n",
        "\n",
        "# Prepare features and target\n",
        "X = adult_dataset.drop('income', axis=1)\n",
        "y = adult_dataset['income']\n",
        "\n",
        "# Handle categorical variables if any (example using get_dummies)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'n_estimators': [100, 150, 200],\n",
        "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
        "    'subsample': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Setup the grid search\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "\n",
        "# Fit grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best accuracy found: \", grid_search.best_score_)\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_metrics = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy:.2f}')\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkddPfYwNnyu"
      },
      "source": [
        "Exp 4 Bayesian optimization for XGBoost model adult_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0adsk0wdlG-H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "\n",
        "# Assuming 'income' is the target and it is categorical\n",
        "le = LabelEncoder()\n",
        "adult_dataset['income'] = le.fit_transform(adult_dataset['income'])\n",
        "\n",
        "# Prepare features and target\n",
        "X = adult_dataset.drop('income', axis=1)\n",
        "y = adult_dataset['income']\n",
        "\n",
        "# Handle categorical variables if any (example using get_dummies)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define search spaces\n",
        "search_spaces = {\n",
        "    'max_depth': Integer(3, 10),\n",
        "    'learning_rate': Real(0.01, 0.2),\n",
        "    'n_estimators': Integer(50, 300),\n",
        "    'colsample_bytree': Real(0.3, 1.0),\n",
        "    'subsample': Real(0.6, 1.0)\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "\n",
        "# Initialize Bayesian optimization\n",
        "opt = BayesSearchCV(xgb_classifier, search_spaces, n_iter=32, scoring='accuracy', cv=3, n_jobs=-1, random_state=0)\n",
        "\n",
        "# Fit the model\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(\"Best parameters found: \", opt.best_params_)\n",
        "print(\"Best score found: \", opt.best_score_)\n",
        "\n",
        "# Use the best estimator to make predictions\n",
        "y_pred = opt.best_estimator_.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy on Test Set: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a82G6lmlHAX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5NWhTlSlHDt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}